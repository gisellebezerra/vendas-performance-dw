# üìä Projeto: Otimiza√ß√£o de Margem e Performance de Vendas

Este projeto consiste na implementa√ß√£o de uma infraestrutura de dados anal√≠tica (**Data Warehouse**) focada em medir a sa√∫de financeira e a efici√™ncia comercial da Northwind. 
A solu√ß√£o transforma dados transacionais brutos em um modelo **Star Schema**, otimizado para an√°lises de lucratividade e performance de vendas.


## üéØ Objetivo do Projeto
O prop√≥sito foi migrar dados de um sistema operacional (OLTP) para um ambiente anal√≠tico (OLAP), permitindo que a empresa identifique:
* **Margem Real:** O faturamento l√≠quido exato ap√≥s a aplica√ß√£o de descontos.
* **Desempenho Geogr√°fico:** Performance de vendas por territ√≥rio e cidade.
* **Produtividade:** Ranking de funcion√°rios por volume financeiro gerado.
* **Sazonalidade:** Tend√™ncias de vendas atrav√©s de uma dimens√£o de tempo dedicada.

## üß© Modelo L√≥gico (Star Schema)
Abaixo, a representa√ß√£o visual das tabelas e seus relacionamentos:

![Modelo L√≥gico do DW](images/modelo_logico_dw_venda.png)

## üèóÔ∏è Arquitetura do Data Warehouse
A modelagem seguiu a metodologia **Star Schema** (Modelo Estrela), garantindo simplicidade para o usu√°rio final e alta performance em consultas anal√≠ticas.

### 1. Tabela Fato (`fato_venda`)
A pe√ßa central que armazena as m√©tricas quantitativas e chaves estrangeiras.
* **C√°lculo de Valor L√≠quido:** Implementa√ß√£o da l√≥gica `(Pre√ßo * Quantidade) - Desconto` diretamente no processo de carga.
* **Granularidade:** N√≠vel de item de pedido para permitir drill-down detalhado/e uma an√°lise explorat√≥rica dos dados.

### 2. Dimens√µes (O Contexto)
* **`dim_produtos`**: Consolida informa√ß√µes de categorias e fornecedores.
* **`dim_funcionario`**: Atributos dos vendedores respons√°veis pelas vendas.
* **`dim_territorio`**: Estrutura geogr√°fica baseada nos dados de envio.
* **`dim_tempo`**: Dimens√£o inteligente gerada via SQL para an√°lises temporais completas (Trimestre, M√™s, Dia da Semana).

## üõ†Ô∏è Destaques T√©cnicos e Engenharia
* **Precis√£o Financeira:** Uso do tipo `NUMERIC(18,2)` para garantir c√°lculos exatos, evitando os erros de precis√£o comuns do tipo `FLOAT`.
* **Transforma√ß√£o via SQL (ETL):** Todo o processo de limpeza e carga foi realizado com comandos `INSERT INTO ... SELECT` e `INNER JOINs`, transformando chaves naturais em chaves substitutas (surrogate keys).
* **Integridade de Dados:** Configura√ß√£o de restri√ß√µes de chave (PK/FK) para assegurar a consist√™ncia dos dados anal√≠ticos.

## üöÄ Tecnologias Utilizadas
* **PostgreSQL:** SGBD para hospedagem do Data Warehouse.
* **SQL:** DDL e DML para estrutura√ß√£o e transforma√ß√£o dos dados.
* **Modelagem Dimensional:** Padr√µes de projeto Star Schema.
* **Business Intelligence & Analytics (Power BI):** A camada de visualiza√ß√£o foi conectada diretamente ao Data Warehouse para transformar as tabelas dimensionais em insights estrat√©gicos. O foco do dashboard foi a lucratividade e o controle de eros√£o de margem.

## üìÇ Estrutura de Arquivos
* `sql/01_schema_setup.sql`: Cria√ß√£o das tabelas e schemas.
* `sql/02_populate_dims.sql`: Scripts de carga das dimens√µes.
* `sql/03_load_fact.sql`: L√≥gica de transforma√ß√£o e carga da tabela fato.
* `sql/04_analises_exploratorias.sql`:An√°lises explorat√≥rias.
* `sql/04_analises_exploratorias.sql`:Dashboard.

## üõ†Ô∏è Como Reproduzir este Data Warehouse

Para configurar este ambiente localmente, siga os passos abaixo:

1. **Pr√©-requisitos:** Ter o PostgreSQL instalado e a base de dados original `base_projeto_vendas.sql` carregada no schema `public`.
2. **Execu√ß√£o dos Scripts:** Com a base `base_projeto_vendas.sql` ativa, execute os arquivos da pasta `/sql` na ordem num√©rica:
   - `sql/01_schema_setup.sql`: Cria o schema e as tabelas vazias.
   - `sql/02_populate_dims.sql`: Processa e popula as tabelas de Dimens√£o.
   - `sql/03_load_fact.sql`: Executa a l√≥gica de neg√≥cio e popula a tabela Fato.
3. **Valida√ß√£o:** Utilize o arquivo `sql/04_analises_exploratorias.sql` para validar se os dados foram carregados corretamente e extrair os primeiros insights.
