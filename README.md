# ğŸ“Š Projeto: OtimizaÃ§Ã£o de Margem e Performance de Vendas

Este projeto consiste na implementaÃ§Ã£o de uma infraestrutura de dados analÃ­tica (**Data Warehouse**) focada em medir a saÃºde financeira e a eficiÃªncia comercial da Northwind. 
A soluÃ§Ã£o transforma dados transacionais brutos em um modelo **Star Schema**, otimizado para anÃ¡lises de lucratividade e performance de vendas.


## ğŸ¯ Objetivo do Projeto
O propÃ³sito foi migrar dados de um sistema operacional (OLTP) para um ambiente analÃ­tico (OLAP), permitindo que a empresa identifique:
* **Margem Real:** O faturamento lÃ­quido exato apÃ³s a aplicaÃ§Ã£o de descontos.
* **Desempenho GeogrÃ¡fico:** Performance de vendas por territÃ³rio e cidade.
* **Produtividade:** Ranking de funcionÃ¡rios por volume financeiro gerado.
* **Sazonalidade:** TendÃªncias de vendas atravÃ©s de uma dimensÃ£o de tempo dedicada.

## ğŸ—ï¸ Arquitetura do Data Warehouse
A modelagem seguiu a metodologia **Star Schema** (Modelo Estrela), garantindo simplicidade para o usuÃ¡rio final e alta performance em consultas analÃ­ticas.

### 1. Tabela Fato (`fato_venda`)
A peÃ§a central que armazena as mÃ©tricas quantitativas e chaves estrangeiras.
* **CÃ¡lculo de Valor LÃ­quido:** ImplementaÃ§Ã£o da lÃ³gica `(PreÃ§o * Quantidade) - Desconto` diretamente no processo de carga.
* **Granularidade:** NÃ­vel de item de pedido para permitir drill-down detalhado/e uma anÃ¡lise exploratÃ³rica dos dados.

### 2. DimensÃµes (O Contexto)
* **`dim_produtos`**: Consolida informaÃ§Ãµes de categorias e fornecedores.
* **`dim_funcionario`**: Atributos dos vendedores responsÃ¡veis pelas vendas.
* **`dim_territorio`**: Estrutura geogrÃ¡fica baseada nos dados de envio.
* **`dim_tempo`**: DimensÃ£o inteligente gerada via SQL para anÃ¡lises temporais completas (Trimestre, MÃªs, Dia da Semana).


## ğŸ› ï¸ Destaques TÃ©cnicos e Engenharia
* **PrecisÃ£o Financeira:** Uso do tipo `NUMERIC(18,2)` para garantir cÃ¡lculos exatos, evitando os erros de precisÃ£o comuns do tipo `FLOAT`.
* **TransformaÃ§Ã£o via SQL (ETL):** Todo o processo de limpeza e carga foi realizado com comandos `INSERT INTO ... SELECT` e `INNER JOINs`, transformando chaves naturais em chaves substitutas (surrogate keys).
* **Integridade de Dados:** ConfiguraÃ§Ã£o de restriÃ§Ãµes de chave (PK/FK) para assegurar a consistÃªncia dos dados analÃ­ticos.

## ğŸš€ Tecnologias Utilizadas
* **PostgreSQL:** SGBD para hospedagem do Data Warehouse.
* **SQL:** DDL e DML para estruturaÃ§Ã£o e transformaÃ§Ã£o dos dados.
* **Modelagem Dimensional:** PadrÃµes de projeto Star Schema.

## ğŸ“‚ Estrutura de Arquivos
* `sql/01_schema_setup.sql`: CriaÃ§Ã£o das tabelas e schemas.
* `sql/02_populate_dims.sql`: Scripts de carga das dimensÃµes.
* `sql/03_load_fact.sql`: LÃ³gica de transformaÃ§Ã£o e carga da tabela fato.

---

